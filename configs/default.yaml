pipeline:
  backend: "gemini"          # "gemini" or "qwen"
  modules:
    behavior: true            # always on
    detection: true           # YOLOv8-nano
    depth: false              # Depth Anything V2 Small
    audio: true               # Whisper / Gemini audio

frame_extraction:
  fps: 1.0
  max_frames: 60
  resize_width: 640

detection:
  model: "yolov8n.pt"
  confidence: 0.5
  imgsz: 640

depth:
  model: "vits"              # vits = Small variant
  device: "cuda"

audio:
  model: "small"             # whisper-small
  device: "cpu"              # always CPU to save VRAM
  language: null             # auto-detect

vlm:
  gemini:
    model: "gemini-2.0-flash"
    temperature: 0.1
    max_output_tokens: 8192
  qwen:
    model: "Qwen/Qwen2.5-VL-3B-Instruct"
    quantize: "4bit"
    device: "cuda"
    max_new_tokens: 4096

graph:
  min_confidence: 0.3

output:
  save_annotated_video: true
  save_depth_maps: false
  save_json: true
  results_dir: "results"